import datetime
import json

import requests


def get_access_token():
"""
Replace the following with your actual credentials
"""
# Define your organization ID and IMS Org ID
org_id = "your_organization_id"
ims_org_id = "your_ims_org_id"

# Define your API key
api_key = "your_api_key"

# Define your sandbox name
sandbox_name = "your_sandbox_name"

# URL to generate access token
token_url = f"https://ims.{sandbox_name}.adobe.io/ims/token/oauth2/token"

# Payload for generating access token
payload = {
	"client_id": api_key,
	"client_secret": "",  # Leave this blank for Experience Cloud APIs
	"grant_type": "client_credentials",
	"scope": "read_all"
}

# Make a POST request to get the access token
response = requests.post(token_url, data=payload)
response.raise_for_status()

# Extract the access token from the response
access_token = response.json()["access_token"]
return access_token


def list_batches(dataset_id, access_token):
"""
Lists all batches for a specific dataset ID on the current date
"""
# Define the base URL for the Data Access API
base_url = "https://platform.adobe.io/data/foundation/export"

# Today's date in YYYY-MM-DD format
today = datetime.datetime.now().strftime("%Y-%m-%d")

# Construct the URL for listing batches
url = f"{base_url}/datasets/{dataset_id}/batches?status=succeeded&startDate={today}&endDate={today}"

# Set the headers with the access token and other required information
headers = {
	"Authorization": f"Bearer {access_token}",
	"x-gw-ims-org-id": ims_org_id,
	"x-api-key": api_key,
	"x-sandbox-name": sandbox_name,
}

# Make a GET request to list the batches
response = requests.get(url, headers=headers)
response.raise_for_status()

# Parse the JSON response and return the list of batches
return json.loads(response.content)["data"]


def main():
# Replace this with your actual dataset ID
dataset_id = "your_dataset_id"

# Get the access token
access_token = get_access_token()

# List the batches for today
batches = list_batches(dataset_id, access_token)

# Print the information about each batch
print(f"Found a total of {len(batches)} batches for dataset {dataset_id} today:")
for batch in batches:
	print(f"\tBatch ID: {batch['id']}")
	print(f"\tStatus: {batch['status']}")
	print(f"\tCreated at: {batch['createdAt']}")


if __name__ == "__main__":
main()










####################################################


#chatgpt

def get_access_token(client_id, client_secret, ims_org_id):
auth_url = f"https://ims-na1.adobelogin.com/ims/exchange/jwt?client_id={client_id}&client_secret={client_secret}&jwt_token=your-jwt-token"
response = requests.post(auth_url)
if response.status_code == 200:
	auth_data = response.json()
	access_token = auth_data["access_token"]
	return access_token
else:
	raise Exception(f"Failed to obtain access token. Status code: {response.status_code}")


def list_batches_for_today(access_token, dataset_id):
    today = datetime.date.today().isoformat()
    base_url = f"https://platform.adobe.io/data/foundation/import/batches/{dataset_id}"
    
    headers = {
        "Authorization": f"Bearer {access_token}",
        "x-api-key": client_id
    }

    params = {
        "ims_org_id": ims_org_id,
        "from": today,
        "to": today
    }

    response = requests.get(base_url, headers=headers, params=params)

    if response.status_code == 200:
        batches = response.json()
        return batches
    else:
        raise Exception(f"Failed to list batches. Status code: {response.status_code}")


def list_batches_for_today(access_token, dataset_id):
    today = datetime.date.today().isoformat()
    base_url = f"https://platform.adobe.io/data/foundation/import/batches/{dataset_id}"
    
    headers = {
        "Authorization": f"Bearer {access_token}",
        "x-api-key": client_id
    }

    params = {
        "ims_org_id": ims_org_id,
        "from": today,
        "to": today
    }

    response = requests.get(base_url, headers=headers, params=params)

    if response.status_code == 200:
        batches = response.json()
        return batches
    else:
        raise Exception(f"Failed to list batches. Status code: {response.status_code}")





import requests
import datetime

# Define your AEP API endpoint and parameters
aep_endpoint = "https://platform.adobe.io/data/foundation/catalog/batches"
access_token = "YOUR_ACCESS_TOKEN"
api_key = "YOUR_API_KEY"
org_id = "YOUR_ORG_ID"
sandbox_name = "YOUR_SANDBOX_NAME"
dataset_id = "YOUR_DATASET_ID"

# Set the start time to midnight UTC
start_time_utc = datetime.datetime.utcnow().replace(hour=0, minute=0, second=0, microsecond=0)

# Convert the start time to a Unix timestamp
start_timestamp = int(start_time_utc.timestamp())

sort_by = "YOUR_SORT_BY"

# Set up headers
headers = {
    "Authorization": f"Bearer {access_token}",
    "x-api-key": api_key,
    "x-gw-ims-org-id": org_id,
    "x-sandbox-name": sandbox_name,
}

# Define query parameters to filter batches by dataset ID and createdAfter timestamp
params = {
    "dataSet": dataset_id,
    "createdAfter": start_timestamp,
    "sort": sort_by,
}

# Make the GET request to filter batches
response = requests.get(aep_endpoint, headers=headers, params=params)

if response.status_code == 200:
    # Parse the JSON response
    filtered_batches = response.json()
    
    # Print the filtered batches
    print("Filtered Batches:")
    for batch in filtered_batches:
        print(f"Batch ID: {batch['id']}, Created Date: {batch['createdDate']}")
else:
    print(f"Error: {response.status_code} - {response.text}")
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	import requests
import datetime
import time

# Define your AEP API endpoint and parameters
aep_endpoint = "https://platform.adobe.io/data/foundation/catalog/batches"
access_token = "YOUR_ACCESS_TOKEN"
api_key = "YOUR_API_KEY"
org_id = "YOUR_ORG_ID"
sandbox_name = "YOUR_SANDBOX_NAME"
dataset_id = "YOUR_DATASET_ID"
sort_by = "YOUR_SORT_BY"
batch_limit = 1000  # The number of batches to retrieve per page
page = 1  # Initialize the page number

# Set the initial start time to the current time minus 2 minutes
start_time_utc = datetime.datetime.utcnow() - datetime.timedelta(minutes=2)

while True:
    # Calculate the end time as the current time
    end_time_utc = datetime.datetime.utcnow()

    # Convert start and end times to Unix timestamps
    start_timestamp = int(start_time_utc.timestamp())
    end_timestamp = int(end_time_utc.timestamp())

    # Set up headers
    headers = {
        "Authorization": f"Bearer {access_token}",
        "x-api-key": api_key,
        "x-gw-ims-org-id": org_id,
        "x-sandbox-name": sandbox_name,
    }

    # Define query parameters to filter batches by dataset ID, started, completed, and limit
    params = {
        "dataSet": dataset_id,
        "started": f"{start_timestamp},{end_timestamp}",
        "sort": sort_by,
        "limit": batch_limit,
        "page": page,
    }

    # Make the GET request to filter batches for the current time range
    response = requests.get(aep_endpoint, headers=headers, params=params)

    if response.status_code == 200:
        # Parse the JSON response and append batches to the list
        current_page_batches = response.json()
        if len(current_page_batches) > 0:
            print("Batches within the time range:")
            for batch in current_page_batches:
                print(f"Batch ID: {batch['id']}, Created Date: {batch['createdDate']}")

        # If the number of retrieved batches is less than the batch limit, break the loop
        if len(current_page_batches) < batch_limit:
            break

        # Increment the page number for the next request
        page += 1

        # Update the start time for the next iteration
        start_time_utc = end_time_utc
    else:
        print(f"Error: {response.status_code} - {response.text}")

    # Wait for 2 minutes before the next iteration
    time.sleep(120)  # Sleep for 2 minutes (120 seconds)

