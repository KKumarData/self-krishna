@pytest.mark.parametrize("dag_id, expected_tasks", [
("example_dag", ["task_1", "task_2", "task_3"]),
("another_example_dag", ["task_A", "task_B", "task_C"])
])

def test_dag_structure(dag_id, expected_tasks):
    dag = get_dag(dag_id)
    assert len(dag.tasks) == len(expected_tasks)
    for task in dag.tasks:
    assert task.task_id in expected_tasks

def test_task_dependencies():
    dag = get_dag("example_dag")
    task_1 = get_task(dag, "task_1")
    task_2 = get_task(dag, "task_2")
    task_3 = get_task(dag, "task_3")
    assert task_2.upstream_task_ids == [task_1.task_id]
    assert task_3.upstream_task_ids == [task_2.task_id]

def test_task_execution_time():
    dag = get_dag("example_dag")
    task_1 = get_task(dag, "task_1")
    task_2 = get_task(dag, "task_2")
    task_3 = get_task(dag, "task_3")
    assert task_1.execution_time == datetime.timedelta(hours=1)
    assert task_2.execution_time == datetime.timedelta(hours=2)
    assert task_3.execution_time == datetime.timedelta(hours=3)
    
    
def test_dag_validation():
# Get a list of all DAGs in the airflow DAGs directory
    dags = [dag for dag in os.listdir(AIRFLOW_DAGS_DIRECTORY) if dag.endswith('.py')]       
        
    # Iterate through each DAG and test the tasks in each DAG
    for dag in dags:
        try:
            # Load the DAG and check if it is valid
            dag_id = os.path.splitext(dag)[0]
            parsed_dag = parse_dag_file(dag_id, AIRFLOW_DAGS_DIRECTORY)
            assert parsed_dag is not None, f"DAG {dag_id} is invalid"
            
            # Check if all tasks in the DAG are valid
            for task in parsed_dag.tasks:
                # Get the task instance and run a dry run to check if it is valid
                task_instance = task.get_instance(execution_date=datetime.now())
                task_instance.dry_run()
                
                # Check if the task's dependencies are valid
                for t in task.upstream_list:
                    assert t.operator is not None, f"Task {t.task_id} in DAG {dag_id} has an invalid operator"
        except Exception as e:
            raise Exception(f"Error while validating tasks in DAG {dag_id}: {e}")
        
        
        
    # Iterate through each DAG and test the tasks in each DAG
    for dag in dags:
        try:
            # Load the DAG and check if it is valid
            dag_id = os.path.splitext(dag)[0]
            parsed_dag = parse_dag_file(dag_id, AIRFLOW_DAGS_DIRECTORY)
            assert parsed_dag is not None, f"DAG {dag_id} is invalid"
            
            # Check if all tasks in the DAG are executed successfully
            for task in parsed_dag.tasks:
                # Get the task instance and run it
                task_instance = task.get_instance(execution_date=datetime.now())
                task_instance.run()
                
                # Check if the task was executed successfully
                assert task_instance.state == 'success', f"Task {task.task_id} in DAG {dag_id} was not executed successfully"
        except Exception as e:
            raise Exception(f"Error while executing tasks in DAG {dag_id}: {e}")
        