from pyspark.sql import SparkSession
from pyspark.sql.functions import current_timestamp, hash, udf, concat

# Create a SparkSession
spark = SparkSession.builder.appName("DataFrame Generator").getOrCreate()

# Define the schema for the DataFrame
schema = StructType([
    StructField("timestamp", TimestampType(), True),
    StructField("hash_key", ByteType(), True),
    StructField("unique_id", StringType(), True)
])

# Define the partition keys or natural keys to use for the hash
partition_keys = ["key1", "key2", "key3"]

# Define a user-defined function (UDF) to generate the hash of the partition keys
hash_udf = udf(lambda x: hash(tuple(x)), ByteType())

# Generate a DataFrame with the timestamp, hash, and unique ID columns
df = spark.createDataFrame(
    [(current_timestamp(), hash_udf(struct(partition_keys)), concat(current_timestamp(), hash_udf(struct(partition_keys))))], schema
)

# Show the resulting DataFrame
df.show()
