####################################################################################
Reading a CSV file
This code reads a CSV file and prints the first few rows of data:
####################################################################################

# Load the CSV data into a DataFrame
df = spark.read.csv('data.csv')

# Print the first few rows of the DataFrame
df.show()
####################################################################################
Writing a CSV file
This code writes a DataFrame to a CSV file:
####################################################################################

# Write the DataFrame to a CSV file
df.write.csv('data.csv')

####################################################################################
Filtering a DataFrame
This code filters a DataFrame to only include rows where the value in the "age" column is greater than 30:
####################################################################################

# Filter the DataFrame to only include rows where the value in the "age" column is greater than 30
filtered_df = df.filter(df['age'] > 30)

# Print the first few rows of the filtered DataFrame
filtered_df.show()

####################################################################################
Aggregating a DataFrame
This code calculates the average value in the "age" column of a DataFrame:
####################################################################################


# Import the functions module
from pyspark.sql.functions import *

# Calculate the average value in the "age" column
average_age = df.agg(avg(df['age'])).first()[0]

# Print the average age
print(average_age)